# This model uses mechanisms to construct a cost matrix and do the matching to projected slots
# So there won't be any need for any other feature, like shape, color, CoM, etc. However, as opposed to 
# inertia_balls_saae_contrastive_enc_only, this model uses both the loss in the latent space and the
# the reconstruction loss to do object-centric learning.

_target_: src.models.inertia_balls_mechanism_match_recons.Inert

defaults:
  - scheduler_config: null # options: reduce_on_plateau, linear, polynomial
  - optimizer: adamw # options: adamw, adam
  - encoder: slot_attention_autoencoder # options: resnet18_encoder, difference_model, slot_attention_autoencoder, slot_attention_encoder
  - additional_logger: reconstruction_logger


visualization_method: "clevr" # 2D

w_latent_loss: 100.0
w_recons_loss: 10.0
pair_recons: False
w_similarity_loss: 1.0
wait_steps: 0 # 2000
linear_steps: 1 # 3000

# options: 
#   constrained_lp uses cvxpylayers to solve a batch of constrained linear programs
#   lin_sum_assignment uses scipy.optimize.lin_sum_assignment to solve a bipartite matching
#   assuming that initializing slots similarly at t,t+1 preserves their ordering
ball_matching: False
latent_matching: "lin_sum_assignment" # "lin_sum_assignment", "constrained_lp", "argmin"
double_matching: False
rm_background_in_matching: True # whether to remove or not the slots corresponding to the background when doing the matching
use_all_balls_mcc: False
known_action: True
# model_name_or_path: ${work_dir}/models/

# full ckpt containing state_dict, callbacks, optimizer, hyperparameters, etc.
pl_model_ckpt_path: null
# set this to null to train from scratch.  NOTE: This path (.pt) only contains the 
# state_dict (to be flexible), if the full ckpt is required (not flexible w/ 
# different # of slots, then load .ckpt file)
encoder_ckpt_path: ${retrieve_encoder_state_dict:${model.pl_model_ckpt_path}}
encoder_freeze: False
# ---------- not used for now ----------
# based on the flags, we will either load the whole state_dict and freeze the encoder-decoder, or
# we will only freeze the slot attention module and let the rest (enc-dec) be fine-tuned, or
# we will only freeze the attention module parameters (k,q,v) and let the rest of the param of
# slot attention to be trained.
slot_attention_freeze_only: False
attention_key_freeze_only: False

n_balls: ${datamodule.n_balls}
n_latents: ${mult_int:2,${model.n_balls}}
sparsity_degree: ${datamodule.sparsity_degree}
known_mechanism: ${datamodule.known_mechanism}
signed_change: True # ${datamodule.dataset.signed}
baseline: True
base_architecture: "resnet18"

contrastive:
    _target_: slot_based_disentanglement.models.contrastive_pl.Contrastive
    base_architecture: ${model.base_architecture}
        
    alpha: 0.0
    baseline: ${model.baseline}
    normalize: True
    normalize_both: True
    p_norm: 2
    

# This model doesn't match to any target feature (like color, CoM, etc.), rather directly projects slots to target
# latent dimension and does the matching based on the cost matrix constructed by mechanism
# predictions per slot projection at time 't' and comparing them to slot projections at t+1
z_dim: 2
disentangle_z_dim: 2
target_property_indices: [0,2,4]

logging_name: "${model.encoder.slot_attention.name}_${datamodule.datamodule_name}_${datamodule.dataset_name}_contrastive_recons_zdim_${datamodule.z_dim}/n_balls_${datamodule.n_balls}/matching_${model.ball_matching}_${datamodule.color_selection}_${model.latent_matching}_known_mech_${model.known_mechanism}_sparsity_${datamodule.sparsity_degree}_z_dis_${model.disentangle_z_dim}"
logging_name_without_subdir: "SA_${datamodule.datamodule_name}_contrastive_recons_zdim_${datamodule.z_dim}_n_balls_${datamodule.n_balls}"
# set this to null to train from scratch
projection_to_z_ckpt_path: null
projection_to_z_freeze: False

# projection_to_z:
#   fc1:
#     _target_: torch.nn.Linear
#     in_features: ${model.encoder.slot_size} # 32
#     out_features: ${mult:${model.encoder.slot_size}, 0.5} # 32 * 0.5
#     bias: False

#   fc1_nonlinearity:
#     _target_: torch.nn.ReLU 

#   fc2:
#     _target_: torch.nn.Linear
#     in_features: ${model.projection_to_z.fc1.out_features} # 16
#     out_features: ${mult:${model.projection_to_z.fc1.out_features}, 0.5} # 16 * 0.5
#     bias: False

#   fc2_nonlinearity:
#     _target_: torch.nn.Tanh 
  
#   fc3:
#     _target_: torch.nn.Linear
#     in_features: ${model.projection_to_z.fc2.out_features}
#     out_features: ${model.z_dim} # 2
#     bias: False

#   # fc3_nonlinearity:
#   #   _target_: torch.nn. 

separate_projection_head: True

projection_to_z:
  fc1:
    _target_: torch.nn.Linear
    in_features: ${model.encoder.slot_size} # 64
    out_features: ${mult:${model.encoder.slot_size}, 0.5} # 64 * 0.5
    # out_features: ${mult:${model.encoder.slot_size}, ${model.encoder.slot_size}} # 64
    # out_features: 1
    # out_features: ${model.z_dim}
    bias: True

  fc1_nonlinearity:
    _target_: torch.nn.ReLU 
  
  fc2:
    _target_: torch.nn.Linear
    in_features: ${model.projection_to_z.fc1.out_features}
    # out_features: ${model.projection_to_z.fc1.out_features}
    out_features: 1
    # out_features: ${model.z_dim}
    bias: True

  # fc2_nonlinearity:
  #   _target_: torch.nn.ReLU 

  # fc3:
  #   _target_: torch.nn.Linear
  #   in_features: ${model.projection_to_z.fc2.out_features} # 16
  #   out_features: ${mult:${model.projection_to_z.fc2.out_features}, 0.5} # 16 * 0.5
  #   bias: False

  # fc3_nonlinearity:
  #   _target_: torch.nn.ReLU 
  
  # fc4:
  #   _target_: torch.nn.Linear
  #   in_features: ${model.projection_to_z.fc3.out_features} # 16
  #   # out_features: ${mult:${model.projection_to_z.fc3.out_features}, 0.5} # 16 * 0.5
  #   out_features: 1 # ${model.z_dim}
  #   bias: False
# ----
  # fc4_nonlinearity:
  #   _target_: torch.nn.ReLU 
  
  # fc5:
  #   _target_: torch.nn.Linear
  #   in_features: ${model.projection_to_z.fc4.out_features}
  #   out_features: 1 # ${model.z_dim}
  #   # out_features: ${model.z_dim}
  #   bias: False

  # # fc3_nonlinearity:
  # #   _target_: torch.nn.ReLU
